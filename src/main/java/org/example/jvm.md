**一.G1的分区机制和停顿预测模型**

***\*二.G1的对象分配效率和垃圾回收效率\*******\*
\****

**
**

**G1如何分配对象+TLAB机制+分区协调机制：**

**G1设计了一套TLAB机制+快速分配机制用来提升分配对象的效率**

**G1设计了一套记忆集+位图+卡表+DCQ+DCQS机制用来提升垃圾回收的效率**

**
**

**一.G1的分区机制和停顿预测模型**

**1.G1垃圾回收器的简介**

**2.HeapRegion*****\*是G1内存管理的基本单位\****

***\*3.ParNew +CMS与G1的内存模型对比\****

***\*4.G1如何设置HeapRegion(HR)的大小\****

***\*5.应该如何设置G1的新生代内存大小\****

***\*6.G1新生代扩展流程(新生代分区扩展流程)\****

***\*7.停顿预测模型和衰减算法\****

***\*
\****

***\*1.G1垃圾回收器的简介\****

***\*(1)垃圾回收\*******\*优先\****

***\*G1垃圾回收器：也可以叫\**垃圾回收优先\**\*\*回收器(Garbage-First，G1)。一句话概括就是：这种垃圾回收器会\*\**\**\**\*优先回收垃圾\*\**\*，\**\*\*不会等空间全部占满然后再进行回收\*\**\**\**\*。\*\**\***

***\*
\****

***\*(2)停顿预测模型\****

***\**\*预测一次回收可以回收的分区数量，以满足我们对停顿时间的要求。\*\**\**\**\*G1最大的特点\*\**\**\**\*：\*\**\**\**\*可以设置每次垃圾回收时的最大停顿时间\*\**\**\**\*，以及\*\**\**\**\*指定在一个长度为M毫秒的时间片段内\*\**\**\**\*，\*\**\**\**\*垃圾回收时间不超N毫秒\*\**\**\**\*。\*\**\***

***\**\*
\*\**\***

***\**\*(3)化整为\*\**\******\*零的\**分区机制**

**ParNew + CMS这种回收器的分区是：新生代、老年代、S区。G1则是把一整块内存分成N个相同大小、灵活可变的分区(Region)，这种灵活可变的Region机制，是G1能够控制停顿时间的核心设计。**

**
**

**2.HeapRegion*****\*是G1内存管理的基本单位\****

***\*G1有如下几种的分区类型：\****

***\*新生代分区\**\**\*\*：\*\**\**\**\*Young Heap Region\*\**\***

***\**\*自由分区\*\**\**\**\*：\*\**\**\**\*Free Heap Region\*\**\***

***\**\*老年代分区\*\**\**\**\*：\*\**\**\**\*Old Heap Region\*\**\***

***\**\*大对象分区\*\**\**\**\*：\*\**\**\**\*Humongous Heap Region\*\**\***

***\*
\****

***\**\*其中\*\**\**\**\*新生代分区\*\**\**\**\*又可分为\*\**\**\**\*Ede\*\*\*\*n\*\**\**\**\*和\*\**\**\**\*Survivor\*\**\**\**\*，\*\**\**\**\*大对象分区\*\**\**\**\*又可分为\*\**\**\**\*大对象头分区\*\**\**\**\*和\*\**\**\**\*大对象连续分区\*\**\**\**\*。\*\**\***

***\*
\****

***\*3.ParNew +CMS\*******\*与G1的内存模型对比\****

ParNew + CMS优势：(小内存停顿很小)

它不用做很多复杂的分区管理，而且小内存垃圾回收不会造成很大停顿。



ParNew + CMS劣势：(大内存停顿很大)

如果给JVM分配64G内存，那么Eden区可能就有20～30G，回收一次Eden区可能就要2～3s，这时请求都可能直接超时了。



传统的分代模型是按照块状来做内存分配的，这种分配方式会存在不足，比如在大内存机器中，会出现一次GC时间过长，导致STW时间较长。严重情况下，还会对用户体验造成比较大的影响。



所以针对大内存场景，诞生了G1这种垃圾回收器。G1的分代模型，通过化整为零，将一个大内存块分割成N个小内存块。然后根据需求，动态分配给新生代、老年代、大对象来使用。同时G1会根据垃圾回收情况动态改变新生代的大小(Region个数)，当然也可能会因此动态改变老年代、大对象分区的大小。

**
**

**4.G1如何设置HeapRegion(HR)的大小**

通过设置参数G1HeapRegionSize来指定大小，默认为0。Region的大小范围是1～32M，同时需要满足2的N次幂。堆分区的个数默认是2048个。

**
**

**(1)Region过****小可能会影响对象分配的性能**

比如Region只有256K，而系统运行创建的对象是几十到几百K，那么JVM在为创建的对象分配空间时：



第一：找到可以使用的Region的难度增加了，导致分配一个对象时要查找Region的次数增多。



第二：跨分区存储的概率增加了。分配对象时，可能需要找多个Region分区。分区越小，就说明同样的Region，可以存储的对象越少。还可能会出现稍微大一点的对象就超过了一个Region的大小，那么就只能跨分区存储。如果一个对象要用多个Region存储，这时分配对象的开销还是比较大的。

**
**

**(2)Region****过大可能会影响GC的性能**

比如Region为64M，那么JVM在进行GC回收时：



第一：Region回收价值的判定很麻烦，对大Region进行回收性价比判断要比小Region难。



第二：回收的判定过程会更加复杂。GC Roots时需要追踪标记对象，然后标记垃圾对象。如果遇到跨代、跨区的对象，还要做一些额外的处理。判断这些对象是否需要回收的过程就会更加复杂，导致回收时间更长。



所以要平衡对象分配效率和垃圾回收效率，设置合理的Region大小来保证对象分配和垃圾回收性能。

**
**

**(3)为什么要设置成2的N次幂**

如果不设置为2的N次幂，那么：



第一：可能会造成内存碎片内存浪费的问题

一般内存的分配都是几个G，比如2048M、4096M或者8G、32G等。如果一个Region = 3M、15M、23M，那么就不能整除出有多少个分区。有可能分区数量不是整数，从而导致内存碎片，有一部分内存没利用上。此外如果需要扩展内存，也是按照2的倍数去进行扩展的。



第二：无法利用2进制计算速度快的特性

计算机底层是二进制的，如果使用非2的N次幂的数字。那么在计算Region数量或自动扩展Region数量时，会无法利用2进制计算速度快的特性。因为位运算速度非常快的，计算2 * 2只需要进行1 << 2，所以设置一个比较合理的Region大小很重要。

**
**

**(4)基于RegionSize的分区数量的变动过程**

在计算RegionSize时，会使用一个参数的默认值2048来计算RegionSize，然后RegionSize会被动态调整成一个合理的值。所以2048只是一个默认值，在使用2048这个值完成计算后：如果RegionSize没有调整，并且堆内存不会动态扩展时，堆分区的数量才是2048，否则分区的数量是会动态变化的。



总结：如果要计算分区大小RegionSize，肯定需要HeapSize。有了HeapSize，就能自动计算出来有多少个分区。因为堆内存很可能会出现变化，所以分区数量会随着堆内存变化而变化。



注意：G1不能手动指定分区个数。按照默认值计算，G1可以管理的最大内存为2048 * 32M = 64G。假设设置xms = 32G，xmx = 128G，则每个Region分区的大小为32M，Region分区个数动态变化范围从1024到4096个。



如果Region越大，那么分配效率就越高，回收效率越低、回收时间越长。如果Region越小，那么分配效率就越低，回收效率越高、回收时间越短。

**
**

***\*5.应该如何设置G1的新生代内存大小\****

必须要满足动态扩展机制 + 停顿预测模型，才能满足设置的停顿时间。

**
**

**(1)如何满足G1新生代的动态扩展机制**

不要指定新生代大小为固定值、不要直接指定Xmn，也不要直接只设置NewRatio、不要指定MaxNewSize = NewSize。



如果确实需要设置新生代的值，那么可以设置成范围。比如MaxNewSize = 100及NewSize = 10，但是这个范围如果设置得不很合理，还是很有可能会有性能问题。

**
**

**(2)为什么要满足G1新生代的动态扩展**

为满足设定的停顿时间，就要进行垃圾回收时间和程序运行时间的平衡。控制回收时间在一个范围内，根据回收时间和内存大小来综合计算。然后动态调整内存分区的占比，来满足回收时间。



如果不做动态调整，那么GC时间过长，就没办法满足停顿时间。动态增加，动态减少，才能调整到一个合理的值。一旦超过了时间范围，就再调整一下。G1新生代的动态扩展，可以实现：动态调整YGC所需要的时间。

**
**

**(3)具体的示例分析**

新生代500个Region，期望停顿时间100ms，新生代填满后要进行GC。多次GC后，G1发现GC时间都不是很长(50ms)，系统运行时间也特别短。也就是GC频率比较高，但GC耗时非常短，说明此时的GC还不是很合理。G1希望让程序运行时间长一些、GC不要那么频繁、同时满足停顿时间。这时候就可以扩展分区，在新生代增加一些Region。原来新生代有500个Region，扩展为1000个Region。



多次GC后，G1发现GC时间特别长(100ms)，甚至有时都超过停顿时间。这时说明GC压力太大了(所以GC时间才特别长)，需要减少一些Region。这时就可以移除新生代的一些Region，让对象填满新生代的速度变快，系统程序运行的时间可以短一点。原来新生代有500个Region，缩减为250个Regiion，从而让GC的时间满足小于期望停顿时间。

**
**

**(4)应该怎么设置G1新生代内存的大小**

第一：不能随便设置参数破坏新生代动态扩展机制

第二：满足用户设定的停顿时间(期望停顿时间)

第三：空闲列表+扩展新分区实现新生代动态扩展

第四：扩展新分区规则(未使用的20%) + 一次扩展的大小上下限(1M和一倍)

第五：自适应扩展空间的依据是-XX:GCTimeRatio，系统运行:GC时间=9:1

**
**

***\*6.G1新生代扩展流程(新生代分区扩展流程)\****

**时机一：**新生代分区列表不够 -> 需要新生代分区列表扩展 -> 找自由分区列表 -> 自由分区列表不够 -> 从堆内存中申请新的分区 -> 加入新生代分区列表中。

**
**

**时机二：**后台线程抽样 -> 程序运行时间 : GC时间 < 9 : 1 (即GC时间超过10%) -> 自动扩展新生代分区列表 -> 找自由分区列表 -> 自由分区列表不够了 -> 从堆内存中申请新分区 -> 加入到新生代分区列表中。

**
**

**7.停顿预测模型和衰减算法**

***\*(1)如何满足用户设定的停顿时间\****

期望停顿时间只是期望值，G1会努力在这个目标停顿时间内完成GC。但G1不能保证，即也可能完不成，比如设置的期望停顿时间太小。

**
**

***\*一.首先要预测\****

预测在停顿时间范围(200ms)内，G1能回收多少垃圾？比如G1预测能在200ms内回收2G的垃圾，那就选择2G内存对应的的Region来进行回收。

**
**

***\*二.预测的依据\****

预测的依据是GC相关的历史数据，所以要获取历次GC相关的运行数据。比如曾经发生的GC、每次GC多久、回收多少垃圾、总的GC时间是多少。***\*
\****

**
**



**三.应该怎么预测**

基本逻辑是：如果目标停顿时间短、就少收点分区，目标停顿时间长、就多收点分区。也就是说，必须要知道，回收能力是多少。



此时历次回收相关的历史数据就派上用场了。可以根据这些历史数据进行计算，看看平均每秒能回收多少垃圾。比如发生3次GC，总共用了200ms回收2G垃圾，那么回收能力是10G/s。然后结合停顿时间，就能计算这次GC在期望停顿时间下能回收多少垃圾。所以需要一个历史数据的分析算法，来帮助G1分析回收能力。

**
**

***\*四.一个简单的分析算法模型\****

求过去10次GC造成多少停顿时间，最终计算出平均每秒能回收多少垃圾。例如过去10次一共收集了10G内存，一共花费了1s，那么200ms能够回收的垃圾就是2G。于是就可以根据这个计算值，选择一定数量的Region分区。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QDoEKpRYCrNTCjFOyVsdIm0jW6l1X8IYrEeBlrt8Pd5GD74olg7a7TvuKibibgXZBX3xh6f8effBlqw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=3)

根据内存动态扩展机制，线性算法是否合理？由于新生代内存可能会动态增加至最大值，新生代和老年代的Region数量也可能在变化。新生代越小回收时间肯定越快，越大需要回收的时间必然越久。而且系统在不断运行时，有时候是高峰期，有时候是低谷期。所以直接简单粗暴的求平均是不合适的。



不能仅使用历次回收的总大小除以总回收时间的平均值作为回收能力，仅仅使用平均值来作为停顿预测模型其实是不太合理的，因为：第一.G1本身是一个不断扩展的模型，第二.系统也一直在不断地运行(有时是高峰期有时是低谷期)。

**
**

**(2)如何设计一个合理的预测算法**

**一.距离本次预测越近的GC其影响权重就越高**

**比如已经发生了3次GC，现在要预测第4次GC。**那么第一次权重是0.2，第二次权重是0.3，第三次GC的权重可能就是0.5。

**
**

**二.G1使用了衰减标准差算法来实现距离本次预测越近权重越高**

衰减标准差算法有一个衰减因子叫α，α是一个小于1的固定值。简单理解就是：衰减因子越小，那么最新的数据对结果的影响就越大，G1的停顿预测模型就是以衰减标准差为理论基础来实现的。

**
**

**三.具体计算模型**

衰减平均计算公式：

- 
- 

```
davg(n) = Vn, n = 1davg(n) = (1 - α) * Vn + α * davg(n - 1), n > 1
```

上述公式中的α为历史数据权值，1-α为最近一次数据权值。α越小，最新的数据对结果影响越大，最近一次的数据对结果影响最大。



例如α = 0.6，GC次数为3，三次分别为：

第一次回收2G，用时200ms。

第二次回收5G，用时300ms。

第三次回收3G，用时500ms。

那么计算结果就如下：

- 
- 
- 

```
davg(1) = 2G / 200msdavg(2) = (1 - 0.6) * 5G / 300ms + 0.6 * 2G / 200msdavg(3) = (1 - 0.6) * 3G / 500ms + 0.6((1 - 0.6) * 5G / 300ms + 0.6 * 2G / 200ms)
```

从这个演变过程中也能看出：计算出来的平均值davg(3)中，权重最大的就是最后一次GC。这样就可以以最合理最精准的方式，预测出本次GC在目标停顿时间范围内能回收多少垃圾。

**
**

**(3)基于****衰减算法模型的垃圾回收过程**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QDoEKpRYCrNTCjFOyVsdIm03FObr5WJtRiayciajfIhdrdibVNTBMeLvjqbEgfye7IicgDFNvZWwTibTmQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=4)

***\*
\****

***\*二.G1的对象分配效率和垃圾回收效率\****

***\*1.无锁化分配\****

**2.TLAB机制的原理**

**3.****借助TLAB分配对象的原理**

***\*4.什么是快速分配 + 什么是慢速分配\****

***\*5.大对象分配的过程 + 与\**\**TLAB的关系\****

***\*6.JVM的最终分配尝试\****

***\*7.G1为了提升GC标记效率做了哪些设计\****

***\*8.卡表和记忆集存储了什么\****

***\*9.RSet记忆集是怎么更新的\****

***\*10.DCQ机制的底层原理\****

***\*11.DCQS机制及GC线程对DCQ的处理\****

**
**

**1.无锁化分配**

***\*(1)G1如何分配一个对象\****

系统程序在创建一个对象时，会先找新生代的Eden区来存储。在G1中，会从Eden区包含的Region里选择一个Region来进行对象的分配。



但是如果有两个线程，同时要找其中一个Region来分配对象，并且这两线程刚好找到这个Region里的同段内存，那么就会出现并发安全问题。

**
**

**(2)如何解决对象创建过程的冲突问题**

一个简单的思路就是加锁。线程1在分配对象时，直接对整个堆内存加锁。分配完成后，再由线程2进行对象分配，此时一定不会出现并发安全问题。



为什么要对整个堆内存进行加锁？因为对象分配的过程是非常复杂的，不仅仅是分配一个对象。还要做引用替换、引用关系处理、Region元数据维护、对象头处理等。只锁一个Region，或只锁一段内存是不够的，因此只能锁整个堆内存。



但是新的问题出现了，这个分配效率很显然非常低，那么应该如何解决这个分配的效率问题？

**
**

**(3)无锁化分配——基于TLAB的快速分配**

想要解决并发安全问题，一般有三种思路：

思路一：使用锁

思路二：使用CAS这种自旋模式(类似锁的思想)

思路三：使用本地缓冲，自己改自己的



G1会使用本地缓冲区来解决并发分配对象的安全和效率问题，整体来说G1提供了两种对象分配策略：

策略一：慢速分配

策略二：基于线程本地分配缓冲(TLAB)的快速分配



TLAB全称就是Thread Local Allocation Buffer，即线程本地分配缓冲。每个线程都会有一个自己的本地分配缓冲区，专门用于对象的快速分配。所以TLAB产生的目的就是为了进行内存快速分配，G1会通过为每个线程分配一个TLAB缓冲区来避免和减少使用锁。



TLAB属于线程的，不同的线程不共享TLAB。线程在分配对象时，会从JVM堆分配一个固定大小的内存区域作为TLAB。然后优先从当前线程的TLAB中分配对象，不需要锁，从而实现无锁化分配即快速分配。

**
**

**2.TLAB机制的原理**

**(1)TLAB是什么 + TLAB是怎么分配的**

**程序创建的对象是由线程创建的，**线程在分配时，也是以一个对象的身份分配出来的，比如创建线程是由Thread对象new出来的。



所以创建一个线程时，也会有一个线程对象需要被分配出来。而事实上，分配TLAB就是和分配线程对象同时进行的。



创建线程，分配线程对象时，会从堆内存分配一个固定大小的内存区域。并且将该区域作为线程的私有缓冲区，这个私有缓冲区就是TLAB。

**
**

**(2)如何确定TLAB大小 + TLAB满了如何处理**

**一.TLAB的大小要有一个平衡点**

**情况一**：如果TLAB过小

会导致TLAB快速被填满，从而导致不断分配新的TLAB，降低分配效率。



情况二：如果TLAB过大

由于TLAB是线程独享，所以TLAB过大会造成内存碎片，拖慢垃圾回收的效率。因为运行过程中，TLAB可能很多内存都没有被使用，造成内存碎片。同时在垃圾回收时，因为要对TLAB做一些判断，所以会拖慢垃圾回收的效率。

**
**

**二.如何确定TLAB的大小**

**TLAB初始化时有一个公式计算：**TLABSize = Eden * 2 * 1% / 线程个数。其中乘以2是因为，JVM的开发者默认TLAB的内存使用服从均匀分布。均匀分布指对象会均匀分布在整个TLAB空间，最终50%的空间会被使用。分配好TLAB后，线程在创建对象时，就会优先通过TLAB来创建对象。

**
**

**三.TLAB满了无法分配对象了会怎么处理**

TLAB满了的处理思路无非两种：

一.重新申请一个TLAB给线程继续分配对象

二.直接通过堆内存分配对象



G1是使用了两者结合的方式来操作的。如果TLAB满了无法分配对象了，就先去申请一个新的TLAB来分配对象。如果无法申请新的TLAB，才通过对堆内存加锁，直接在堆上分配对象。

**
**

**(3)怎么判断TLAB满了**

**一.为什么需要判断TLAB满****了**

**因为TLAB大小分配好后，其大小就固定了，而对象的大小却是不规则的，**所以很有可能会出现对象放不进TLAB的情况。但是TLAB却还有比较大比例的空间没有使用，这时就会造成内存浪费。所以如何判断TLAB满了，是一个比较复杂的事情。

**
**

**二.G1是如何判断TLAB满了**

G1设计了一个refill_waste来判断TLAB满了，refill_waste的含义是一个TLAB可以浪费的最大内存大小是refill_waste。也就是说，一个TLAB中最多可以剩余refill_waste这么多的空闲空间。如果TLAB剩余的空闲空间比refill_waste少，那就代表该TLAB已经满了。



refill_waste的表示一个TLAB中可以浪费的内存的比例，refill_waste的值可以通过TLABRefillWasteFraction来调整。TLABRefillWasteFraction默认值是64，即可以浪费的内存比例为1/64。如果TLAB为1M，那么refill_waste就是16K。

**
**

**(4)TLAB满了怎么办 + 经常满又怎么办**

G1设计的refill_waste不是简单去判断是否满了，其判断过程会比较复杂，具体逻辑如下：

**
**

**一.线程要分配一个对象，首先会从线程持有的TLAB里面进行分配**

如果TLAB剩余空间够了，就直接分配。如果TLAB剩余空间不够，这时就去判断refill_waste。

**
**

**二.此时要对比对象所需空间大小是否大于refill_waste这个最大浪费空间**

如果大于refill_waste，则直接在TLAB外分配，也就是在堆内存里直接分配。如果小于refill_waste，就重新申请一个TLAB，用来存储新创建的对象。

**
**

**三.重新申请新的TLAB时，会根据TLABRefillWasteFraction来动态调整**

动态调整目的是适应当前系统分配对象的情况，动态调整依据是refill_waste和TLAB大小无法满足当前系统的对象分配。因为对象既大于当前TLAB剩余的可用空间，也大于refill_waste。即剩余空间太小了，分配对象经常没办法分配，只能到堆内存加锁分配。所以很显然还没有达到一个更加合理的refill_waste和TLAB大小。因此系统会动态调整TLAB大小和refill_waste大小，直到一个更合理的值。

**
**

**3.借助TLAB分配对象的原理****
**

**(1)TLAB如何分配对象(指针碰撞法)**

对象分配是一个比较复杂的过程，这里我们不关注对象到底怎么创建的，因为它包含了很多东西：比如引用、对象头、对象元数据、各种标记位、对象的klass类型对象、锁标记、GC标记、Rset、卡表等。

**
**

**一.TLAB如何分配一个对象**

分配一个对象时，TLAB是只给当前这一个线程使用的，因此当前线程可以直接找到这个TLAB进行对象的分配。



那么此时就需要知道TLAB是不是满了、或者对象能不能放得下。如果TLAB剩余内存能放得下，就创建对象。如果TLAB剩余内存放不下就进行如下图示的流程：要么直接堆内存创建对象、要么分配新的TLAB给线程，再继续创建对象。



可见对象在TLAB中能不能放得下是很关键的，那么TLAB中用了什么机制来判断能不能放得下的？

**
**

**二.TLAB如何判断对象能否放得下**

一个比较简单的思路是先确定分配出去了哪些空间。由于TLAB是一个很小的空间，而且对象的分配是按照连续内存来分配的，所以可以直接遍历整个TLAB，然后找到第一个没有被使用的内存位置。接着用TLAB结束地址减去第一个没有被使用的内存地址，得到剩余大小，再将TLAB剩余大小和对象大小进行比较。



但这个思路有一个问题：每一次对象分配都要遍历TLAB，是否有必要？其实每次分配新对象的起始地址，就是上一次分配对象的结束地址。所以可以用一个指针(top指针)，记下上次分配对象的结束地址，然后下次直接用这个作为起始位置进行直接分配。



如下图示：在分配对象obj3时，TLAB里的top指针记录的就是obj2对象的结束位置。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15s0iaibH8RW9UK9tYn4YGekwBKPO0wIaF2E9J6QzuKCuvqxvgQbKoKS5rg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=9)

当obj3分配完成时，此时就把指针更新一下，更新到最新的位置上去。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sXic78bnaGqBFMejEDCfh06l17SxJv2GqpcD6ugjqfmRDVDJdF11FfLA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=10)



但是分配对象时肯定不能直接进入TLAB去分配，因为有可能空间会不够用。所以在分配对象时会判断一下剩余内存空间是否能够分配这个对象。



那么具体应该怎么判断剩余内存空间是否能够分配这个对象呢？此时就需要记录一下整个TLAB的结束位置(end指针)。这样在分配对象时，对比下待分配对象的空间(objSize)和剩余的空间即可。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sHdCUpEpbNp1FGziccbqRknCibvyujN9wgoZ3GIT8AB5nUDIEpFK9l9XQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=11)



知道end指针位置，那么判断关系就很容易：

如果objSize <= end - top，可分配对象。

如果objSize > end - top，不能分配对象。



问题：因为TLAB是一个固定的长度，而对象很有可能有的大有的小，所以有可能会产生一部分内存空间无法被使用的情况，也就是产生了内存碎片，那么这个内存碎片应该怎么处理呢？



**
**

**(2)dummy哑元对象的作用是处理TLAB内存碎片**

由于TLAB不大，TLAB大小的计算公式是：(Eden * 2 * 1%）/ 线程个数。所以如果TLAB有内存碎片，实际上也就是比一个普通小对象的大小还要小一点。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sRkvJauiasAsg58iagCibIXfZwhgvMew23D54wRs0BQhCzAauQA2GTgcrw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=12)

对于一个系统来说：可能几百个线程，总共加起来的内存碎片也就几百K到几M之间。所以为了这么小的空间，专门设计一个内存压缩机制，肯定是不太合理的。而且也不太好压缩，因为每个线程都是独立的TLAB。把所有对象压缩一下，进入STW，然后把对象集中放到线程的TLAB吗？如果对象在线程1的TLAB分配，压缩后出现在线程2的TLAB里面，那此时该对象应该由谁管理，所以压缩肯定是不合理的。



所以这块小碎片如果对内存的占用不大，能否直接放弃掉？答案是可以的，而G1也确实是这么做的，这块内存碎片直接放弃不使用。而且在线程申请一个新的TLAB时，这个TLAB也会被废弃掉。这个废弃指的不是直接销毁，而是不再使用该TLAB，进入等待GC状态。



此时会有一个新的问题：在GC时，遍历一个对象，是可以直接跳过这个对象长度的内存的。因为对象属性信息中有对象长度，故遍历对象时拿到对象长度就可跳过。但是TLAB里的小碎片，由于没有对象属性信息，所以不能直接跳过。只能把这块小碎片的内存一点一点进行遍历，这样性能就会下降。



所以G1使用了填充方式来解决遍历碎片空间时性能低下的问题，G1会直接在碎片里面填充一个dummy对象。这样GC遍历到这块内存时：就可以按照dummy对象的长度，跳过这块碎片的遍历。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sFLoX1vxdwOBXBku943xgsdccT8cac5icCHFM5c0iaF028lbFna6RyFXA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=13)



问题：如果没有办法用TLAB分配对象，那么此时应该怎么办？新建一个TLAB？那么如果新建一个TLAB失败了，怎么办？

**
**

**(3****)****如果实在无法在TLAB分配对象，应该怎么处理**

**一.对旧TLAB填充dummy对象**

TLAB剩余内存太小，无法分配对象，会有不同情况：如果对象大于refill_waste，直接通过堆内存分配。如果对象小于refill_waste，这时会重新分配一个TLAB来用。在重新分配一个TLAB之前，会对旧的TLAB填充一个dummy对象。

**
**

**二.分配新TLAB时先快速无锁(CAS)分配再慢速分配(堆加锁)**

重新分配一个TLAB时，先进行快速无锁分配(CAS)，再进行慢速分配(堆加锁)。



快速无锁分配(CAS)：如果通过CAS重新分配一个新TLAB成功，也就是Region分区空间足够使CAS分配TLAB成功，则在新TLAB上分配对象。



慢速分配(堆加锁)：如果通过CAS重新分配一个新TLAB失败，则进行堆加锁分配新TLAB。如Region分区空间不足导致CAS分配TLAB失败，需要将轻量级锁升级到重量级锁。

**
**

**三.堆加锁分配时可能扩展Region分区**

进行堆加锁分配一个新的TLAB时：如果堆加锁分配一个新TLAB成功，就在Region上分配一个新的TLAB(堆加锁分配TLAB成功)。如果堆加锁分配一个新TLAB失败，就尝试扩展分区，申请新的Region(堆加锁分配TLAB失败)。

**
**

**四.扩展Region分区时可能GC + OOM**

扩展分区成功就继续分配对象，扩展分区失败就进行GC垃圾回收。如果垃圾回收的次数超过了某个阈值，就直接结束报OOM异常。



解释一下最后的这个垃圾回收：如果因为内存空间不够，导致无法分配对象时，那么肯定需要垃圾回收。如果垃圾回收后空间还是不够，说明存活对象太多，堆内存实在不够了。这时程序肯定无法分配对象、无法运行，所以准备OOM。那么OOM前，可能还会尝试几次垃圾回收，直到尝试次数达到某个阈值。比如达到了3次回收还是无法分配新对象，才会OOM。

**
**

**4.什么是快速分配 + 什么是慢速分配**

**(1)什么叫快速分配 + 什么叫慢速分配**

分配对象速度快、流程少的就叫快速分配。

分配对象速度慢、流程多的就叫慢速分配。

**
**

***\*快速分配：\****TLAB分配对象的过程就叫做快速分配。多个线程通过TLAB就可以分配对象，不需要加锁就可以并行创建对象。TLAB分配对象具有的特点：创建快、并发度高、无锁化。

![img](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sf8dxFk64s45lSib7OGRAt4icmzibWw3TqicnVUxPYGAH4GxPMdICiaxR53A/640?wx_fmt=other&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**慢速分配：**没有办法使用TLAB快速分配的就是慢速分配。因为慢速分配需要加锁，甚至可能要涉及GC过程，分配的速度会非常慢。

![img](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sn2rzLuJv9NicNtuPgQesaEJr9RWD5CibZMNyg8AsLicZ5TdJXvKu0Yapw/640?wx_fmt=other&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

整个对象分配流程如下，注意上图中的慢速分配包括：慢速TLAB分配 + 慢速对象分配

**
**

**说明一：TLAB剩余内存太小，无法分配对象，则判断refill_waste**

如果对象大小大于refill_waste，直接通过堆内存分配，不进行TLAB分配。如果对象大小小于refill_waste，这时会重新分配一个TLAB。

**
**

**说明二：进行重新分配一个TLAB时，会通过CAS来分配一个新的TLAB**

如果CAS分配成功，则在新的TLAB上分配对象(快速无锁分配)。如果CAS分配失败，就会对堆内存加锁再去分配一个TLAB(慢速分配)。如果堆内存加锁分配新TLAB成功，则可直接在新的TLAB上分配对象。

**
**

**说明三：如果堆内存加锁分配失败，就尝试扩展分区，再申请一些新的Region**

成功扩展了Region就分配TLAB，然后分配对象，如果不成功就进行GC。

**
**

**说明四：如果GC的次数超过了阈值(默认为2次)，就直接结束报OOM异常**

**
**

**(2)慢速分配是什么 + 有几种情况**

慢速分配其实和快速分配相比起来就是多了一些流程，在对象创建这个层面上是没有效率区别的。慢速之所以称为慢速，是因为在分配对象时：需要进行申请内存空间、加锁等一系列耗时的操作，并且慢速分配除了会加锁，还可能涉及到垃圾回收的过程。



慢速分配大概有两种情况：

**
**

***\*情况一：TLAB空间不够，\******要重新申请TLAB，但CAS申请TLAB失败了**

这种情况就是refill_waste判断已通过，TLAB中对象太多，导致对象放不下。此时会创建新的TLAB，但是CAS分配TLAB失败，于是慢速分配TLAB。这个过程的慢速分配是指：慢速分配一个TLAB。

**
**

**情况二：判断无法进行TLAB分配，只能通过堆内存分配对象**

这种情况就是refill_waste判断没通过，对象太大了，导致不能进行TLAB分配。此时会触发慢速分配，并且不是去申请TLAB，而是直接进入慢速分配。也就是直接在堆内存的Eden区去分配对象，这个过程的慢速分配是指慢速分配一个对象。



慢速分配的两种情况如下图示：

![img](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sTra7icXX0raNc51Sic4UcqrO53EHsAmuU4S1OG9lBKMqM0T9LtKnCC9w/640?wx_fmt=other&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

所以快速TLAB分配失败后进入的慢速分配，是个慢速分配TLAB的过程。随后可能会发生更慢的慢速分配，即慢速分配TLAB失败，此时会GC。***\*
\****

**
**

**5.大对象分配的过程 + 与****TLAB的关系**

**(1)什么是大对象 + 大对象的特点**

**一.大对象的定义**

如果一个对象的大小大于RegionSize的一半，那么这个对象就是大对象。也就是ObjSize > RegionSize / 2的时候，就可以称它为大对象。

**
**

**二.大对象的分配**

大对象不会通过新生代来分配，而是直接分配在大对象的Region分区中。问题：为什么它要直接存储在大对象的分区中？不经过新生代？

**
**

**三.大对象的特点**

特点一.大对象太大，并且存活时间可能很长

特点二.大对象数量少

**
**

**二.大对象能否在新生代分配 + TLAB的上限**

如果大对象在新生代分配会怎么样？如果大对象在新生代，那么GC时就会很被动。因为需要来回复制，并且占用的空间还大，每次GC大概率又回收不掉。而且它本身数量相对来说比较少，所以直接将大对象分配到一个单独的区域来管理才比较合理。



G1如何根据大对象的特点来设计TLAB上限？由于大对象的ObjSize > RegionSize / 2，所以G1把TLAB的最大值限定为RegionSize / 2，这样大对象就一定会大于TLAB的大小。然后就可以直接进入慢速分配，到对应的Region里去。

**
**

**(2)G1设定****TLAB最大值为大对象最小值****的原因**

***\*原因一：\****大对象一般比较少，如果进入TLAB则会导致普通对象慢速分配

一个系统产生的大对象一般是比较少的，如果一个大对象来了就占满TLAB了或占用多个TLAB，那么会造成其他普通对象需要进入慢速分配。大对象占满了TLAB后，其他对象就需要重新分配新的TLAB，这就降低系统的整体效率。



***\*原因\*******\*二：\****在GC时不方便标记大对象

一个大对象引用的东西可能比较多，引用它的可能也比较多，所以GC时不太方便去标记大对象。



***\*原因三\*******\*：\****大对象成为垃圾对象的概率小，不适合在GC过程中来回复制

新生代GC不想管大对象，并且管理起来影响效率，所以新生代最好是不管大对象的。因此干脆让大对象直接进行慢速分配，反而能提升一些效率。所以G1设定TLAB上限就是Region的一半大小，TLAB上限即大对象下限，这个设定就会让大对象直接进行慢速分配。

**
**

**(3)大对象的慢速分配和普通的慢速分配有什么区别**

大对象和TLAB中的慢速分配类似，区别是：



**区别一：**大对象分配前会尝试进行垃圾回收



**区别二：**大对象可能因大小的不同，造成分配过程稍微有一些不同



**(4)大对象的慢速分配步骤**

**步骤一：**先判断是否需要GC，需要则尝试垃圾回收 + 启动并发标记。和普通对象的慢速分配不同点在于：大对象分配时，先判断是否需要GC，是否需要启动并发标记，如果需要则尝试进行垃圾回收(YGC或Mixed GC) + 启动并发标记。



**步骤二：**如果大对象大于HeapRegionSize的一半，但小于一个分区的大小。此时一个完整分区就能放得下，可以直接从空闲列表拿一个分区给它。或者空闲列表里面没有，就分配一个新的Region分区，扩展堆分区。



**步骤三：**如果大对象大于一个完整分区的大小，此时就要分配多个Region分区。



**步骤四：**如果上面的分配过程失败，就尝试垃圾回收，然后再继续尝试分配。



**步骤五：**最终成功分配，或失败到一定次数分配失败。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15slE123kUWNuTLS4L24LKYO2M9w5iabek7Eeibn8PbApDibqibVH9uv4YGXQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=18)

**
**

**6.JVM的最终分配尝试**

**(1)大概率会成功的快速 + 慢速尝试**

一般即使内存不够，扩展一下Region，就能获取足够内存做对象分配了。实在不够才会尝试GC，GC之后继续去做分配。



其实百分之九十九点九的概率是可以成功分配的，极端情况下才会出现尝试了好多次分配，最后都还是失败了的情形。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15ssAdo5Kl7A5CzRzJnk2hKaiapRMIC1V6UW5C8RxHsSM69M5e9v4PSfNw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=19)



上图中的1、2、3步就是扩展、回收的过程，很多情况下直接在1、3步就直接成功了。比如通过TLAB去分配对象，那么其实扩展一个新的TLAB就基本成功了，不会走到垃圾回收这一步。



如果扩展TLAB不成功，那么就直接堆内存分配(慢速分配)、扩展分区。如果堆内存分配 + 扩展分区还是不成功，才会尝试触发YGC，再来一次。如果再来一次还是无法成功就只能返回失败了，那么返回失败之后就直接OOM了吗？没有挽救的余地了吗？前面的失败，经历的GC都是先YGC或Mixed GC，然后进入拯救环节。

**
**

**(2)慢速分配失败以后G1会怎么拯救**

首先需要明确：在慢速分配的过程中，肯定是会尝试去GC的，但是触发的GC要么是YGC要么是Mixed GC。那就说明，还没有到山穷水尽的地步，因为还有一个FGC没有用。所以慢速分配失败后肯定不是直接OOM，而会有一个最终的兜底过程。这个过程会进入最恐怖的FGC过程，是极慢极慢的。

**
**

**(3)FGC在哪里触发 + 会执行几次 + 执行的过程中会做什么操作**

如果上面的过程结束后还是没有返回一个对象，代表慢速分配也失败了。过程中进行的GC也无法腾出空间，那就会走向最后一步，触发FGC。这个GC过程会比较复杂，流程图如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/DXGTicJyJ8QBlnzolzib715R3NmiaGOy15sxxOHib6MnFwWezNYg9hZUqx4xXBEOjOUj3IJv1wNuhXWd8pg7ibG0TQQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=20)



一.尝试扩展分区成功就可以分配对象。

二.如果尝试扩展分区不成功，则会进行一次GC。注意这次GC是FGC，但是这次GC不回收软引用。这次GC后会再次尝试分配对象，如果成功了就结束。

三.如果尝试分配对象还是不成功，就进行FGC。这次FGC会把软引用回收掉，然后再次尝试分配对象。如果再次分配对象成功了，就结束返回。如果再次分配对象还是不成功，就只能OOM，无法挽救。



从上面的流程可以看出：假如一次对象分配失败造成了OOM，很有可能会出现大量GC。这也符合有时看GC日志会发现OOM前多了好几次GC记录的情况。

**
**

**(4)总结**

总的来说，对象分配涉及到的GC过程，在不同的阶段是不一样的。比如在使用TLAB进行快速分配的过程中：第一次进入慢速分配，扩展分区失败时，就是YGC或者Mixed GC。再次进入慢速分配，有可能还会执行YGC或者Mixed GC(没达阈值)。当慢速分配也失败时，才会进行最终的尝试。在最终的尝试中，会尝试执行两次FGC。第一次FGC不回收软引用，第二次FGC会回收软引用。



另外，对象分配一般都是进入快速分配，慢速分配的场景比较少：一般是TLAB大小不合理造成短暂慢速分配，或者是大对象的分配直接进入慢速分配。



慢速分配的过程需要的时间非常长，因为要做很多扩展分区的处理、加锁的处理、甚至GC的处理。

**
**

**7.G1为了提升GC标记效率做了哪些设计****
**

**(1)记忆集RSet**

避免跨代遍历对象。记忆集会通过记录跨代的引用关系来避免遍历整个分代如老年代。G1会为每个Region都创建一个RSet记忆集，G1的每个RSet记忆集都会用来存储对应Region里所有对象的引用关系。



G1选择RSet记忆集去记录跨代的引用关系，大大减少了不必要的遍历操作。G1会针对Region去创建RSet记忆集，这也继续减少了不必要的遍历操作。



G1针对Region来创建记忆集的原因是：老年代、新生代、大对象的Region在GC后可能会变化。如果针对每个分代创建记忆集，因为Region不断变化可能有并发问题。如果针对每个分代创建记忆集，老年代回收时会有额外遍历降低效率。



记忆集之需要记录：老年代到新生代的引用关系、老年代到老年代的引用关系。

**
**

**(2)位图BitMap**

描述内存使用(避免并发冲突 + 避免无效遍历未使用内存)。位图就是通过"位"来描述某一块内存的状态的图，位图就是一组二进制位数据，位图的每一个二进制位的0和1都标识了其描述内容的状态。



**问题一：描述内容太少**

因为位图只有0和1这样的标记，只能证明是否有引用关系。但是JVM在垃圾回收时不单单只需要是否引用这个信息，它还需要一些其它的描述信息：比如使用量、内存起始位置等。否则GC可能因为信息缺乏，导致无法正常回收。



**问题二：增加描述位又会存在位图过大问题**

对于描述信息太少的问题，只能通过增加描述位来增加描述信息。比如不用一个位来描述一个字，而是使用一个字节来描述一个字。从使用1个二进制位描述64位内存的信息，到使用8个二进制位来描述64位内存的信息，这样就可以解决描述信息太少的问题。但是新的问题来了：此时一个位图占用的内存过大了，例如一个Region的大小是1M。如果用一个字节描述一个字，就意味着需要128K来描述一个Region(1M)。这就相当于占用12.5%的Region空间去描述另外一个Region，这个内存占比就太大了，如果是在32位的机器上，甚至需要25%的空间。



所以使用位图的最大问题，就是额外占用的内存空间太大了。

**
**

**(3)卡表CardTable**

节约记忆集的内存(8个位1个字节描述512字节的引用关系)。G1中的卡表其实就是前面说的位图优化，就是把整个堆内存，按照512字节的粒度，拆分成一个个card，然后一个个card组合起来就形成了一个全局的卡表。卡表中每8个二进制位描述512字节内存的引用关系、使用情况等。



卡表其实就是位图思想的一种实现方式，只是粒度不同罢了。位图使用每一个位来描述对应数据的状态，卡表使用一个字节来描述512字节内存的状态、引用等相关数据。总结来说就是，卡表是位图的增强版。

**
**

**8.卡表和记忆集存储了什么**

**(1)记忆集存储了什么**

记忆集RSet里面存储的是"谁引用了当前Region"的引用信息，G1可以通过这些引用信息去找到引用当前Region的对象。G1通过当前Region的记忆集可以找到：引用了当前Region对象的所有对象所在的Region以及这些对象的位置。



一个RSet是由一个个key-value对组成的：key是引用了当前Region(被引用方)的其他Region(引用方)的地址。value是一个数组，数组元素是引用方的对象所在的卡页在卡表中的坐标，卡页就是512字节的内存页。



所以记忆集存储的不是哪一些对象引用了当前Region，记忆集存储的是对当前Region有引用关系的对象的大概位置信息。也就是对象所在的Region地址 + 对象所在的卡页在卡表中的坐标，粒度相比对象来说会稍微大一些。



一旦发现老年代的对象引用了一个新生代的Region中的对象，那么就会在这个新生代的Region的记忆集中维护一个key-value对。其中key是引用方对象对应的Region的地址，也就是那个老年代的对象所在Region的地址。其中value是一个数组，里面存储的数组元素是老年代对象所在卡页(512字节)在全局卡表中的坐标。



通过记忆集的key，可以快速定位Region，从而避免遍历老年代。通过记忆集的value，可以快速定位对象，从而避免遍历Region。



G1在遍历一个新生代的Region时，就能根据这个Region的记忆集，快速定位到引用该Region的对象所在的Region及这些对象所在的卡页，从而避免对老年代进行全局扫描。

**
**

**(2)卡表存储了什么**

G1中的卡表存储的不是引用关系信息，而是卡页的内存使用情况，比如是否使用、使用多少、GC中的状态信息、以及对应哪一块内存。

**
**

**(3)记忆集和卡表是怎么关联的**

简单来说，RSet记忆集其实就是存储了一些卡表的信息。具体就是对当前Region有引用关系的对象的大概位置信息，也就是对象所在的Region地址 + 对象所在的卡页在卡表中的坐标。

**
**

**(4)RSet在空间和时间上做的平衡**

如果没有RSet + 卡表，那么回收新生代时是需要遍历整个老年代的对象的，非常耗时。为了解决这个问题才引入了RSet + 卡表这两个额外的存储结构。



如果把RSet + 卡表的存储粒度，按每一个对象来存储，也不太合适，因为RSet + 卡表会占用很大的额外内存。



所以RSet + 卡表的机制是对空间和时间做了平衡后设计出来的结果。按照该设计，每次找老年代的引用对象时只需遍历一下对应的卡页即可。而且还可以结合对象的长度去做遍历，也就是按照一个对象长度的内存空间为步长去遍历来提升性能。

**
**

**9.RSet记忆集是怎么更新的****
**

**(1)引用关系发生改变时RSet是否需要更新**

如果有对象引用变更，比如新增对象的引用，或失去对象的引用。此时RSet肯定是要更新的，否则就会出现回收时引用关系错误。回收时可能就会出现把正常对象当垃圾对象，或把垃圾对象当正常对象。所以在引用关系变更时，一定需要更新Rset。



所以接下来有如下问题：每次更新引用关系，RSet一定要立即更新吗？如果不立即更新会有什么影响？如果立即更新会产生什么问题？如果不立即更新的话，又有什么合理的方案？

**
**

**(2)应该什么时候处理Rset的更新操作**

由于一个Region会有一个RSet，一旦发生同一个对象或同一个Region内对象的引用关系变更，那么是会出现并发访问同一个RSet的情况的。所以第一个需要解决的问题就是并发问题，而解决并发问题的最好方式要么是串行化处理、要么是分而治之、要么时间不敏感可用异步队列。



***\*问题一：\****假如使用串行化处理，那么每次引用关系变更，是否可以立即更新RSet？如果每次更新引用关系后立即去加一把锁，然后修改RSet，则肯定是能保证RSet的准确性的。但是这种方式最大的问题就是：虽然保证了准确性，但对象的创建和更新等一系列操作是非常频繁的。如果用这种加锁的方式更新RSet，那么肯定会造成性能问题，毕竟一个Region共享一个RSet。每一次对象的创建和更新等操作，肯定都可能去访问这个RSet，这样对RSet加锁进行串行化处理，必然会造成整体性能的下降。所以不能采取串行化处理的方式，那么应该采取什么方式来处理呢？



**问题二：**假如使用分治思想来处理，那么是否能保证系统运行的效率？使用分治思想，那么就需要把一个RSet分割开来，交给多个线程去处理，同时在最后进行汇总。但是在这个场景下，肯定不能这么做。原因一：首先分治操作需要把RSet分开，那么按照什么维度分开呢？原因二：分治思想因为要分开处理，最后汇总，所以肯定要通过几个线程专门来处理，并且这几个线程最好是固定的，那么这些线程是不是都是系统的工作线程？系统的工作线程专门用来做分治是否合适？如果专门新开几个线程，但本来就有上千个Rset，现在还要分治，那要增加多少线程？原因三：分治处理后的结果如何汇总、何时汇总？所以也不能采取分治思想来处理，那么还有没有什么其他的方案比较合适呢？



**问题三：**RSet的数据什么时候才会用到的？JVM最核心的两大操作就是对象分配和垃圾回收。首先，分配对象时是否需要用到RSet的数据：分配对象时是并不需要用到RSet的数据的。因为G1在分配一个对象时，只需要看内存够不够，剩余空间是否能够分配一个对象。分配完成后，直接更新一下内存的使用情况即可，并不需要借助RSet。然后，垃圾回收时是否需要用到RSet的数据：RSet本身就是为了垃圾回收时更加方便、不需要遍历空间而设计的，所以在垃圾回收时肯定需要用到RSet。那么可以得出一个结论：在大多数时间里，RSet即使需要更新而没有把它更新，其实也无所谓，因为不影响程序运行。因此这个更新RSet的操作应该在垃圾回收前完成，既然是在垃圾回收之前完成，那在程序运行到需要垃圾回收的长时间里，就可以通过后台线程把这个更新的事情处理好即可。***\*
\****

**
**

**(3)G1的脏数据队列—异步消费更新RSet**

基于前面的分析可知，只要在垃圾回收前把所有引用的更新处理好即可。而在垃圾回收前，G1是有大量的时间慢慢更新这个引用关系的。所以G1就设计了一个叫做DCQ(Dirty Card Queue)的队列。在每次有引用关系变更时，就把这个变更操作，发送一个消息到DCQ里，然后有一个专门的线程去异步消费。

**
**

***\*10.DCQ机制的底层原理\****

RSet的更新并不是同步完成的。G1会把所有的引用关系都先放入一个队列中，称为DCQ，然后使用线程来消费这个DCQ队列以完成更新。正常会有G1ConcRefinementThreads个线程处理，除了Refine线程会更新RSet，GC线程或Mutator(Java的应用线程Mutator)也可能会更新RSet。DCQ会通过DCQS来管理，为了能并发地处理，每个Refine线程只负责DCQS中的某几个DCQ。



如果一个队列无限长无限增加，单独一个DCQ，很多线程都往里面写。由于DCQ的消费必须保证顺序性，而且只有一个DCQ。那么不管是写入还是消费，都会有并发写和并发消费的问题的，所以G1设计了二级缓存来解决并发冲突的问题。

**
**

**说明一：第一级缓存是在线程这一层**

每一个工作线程都会关联一个DCQ，一个DCQ对应一个Region，多个工作线程可能会对应同一个DCQ。每个线程在执行引用更新操作时，都会往自己那个DCQ里写入变更信息。如果没有第一级缓存，那么所有工作线程都会关联到一个DCQ。DCQ长度默认是256，如果一个DCQ写满，就重新申请一个新的DCQ，并把这个满了的DCQ提交到第二级缓存DCQ Set。

**
**

**说明二：第二级缓存是在一个DCQ Set里面**

一般叫这个二级缓存为DCQS，在线程持有的DCQ满了以后，会把DCQ提交到DCQS中去。这样就解决了并发写的问题，因为每个线程只写自己持有的DCQ即可，写满了就提交到DCQS，顶多这时会加一个锁。此外，由于一个DCQ对应一个Region，所以按时间消费DCQS里的DCQ时，不需要考虑是否顺序消费的问题。



当Refine线程实在是忙不过来时是怎么处理的？由于Refine线程是直接从DCQS取DCQ去消费的，那么如果Refine线程忙不过来，也就意味着：DCQS已经不能再放下更多满了的DCQ了。此时工作线程的DCQ满时，就会去判断能否提交到DCQS。如果发现不能提交，工作线程就会自己去处理这个DCQ，然后更新RSet。

**
**

***\*11.\**\**DCQS\**\**机制及GC线程对DCQ的处理\****

JVM声明了一个全局的静态变量DCQS，DCQS里面存放的是DCQ。为了性能考虑，所有处理引用关系的线程共享一个DCQS。每个线程(Java的应用线程Mutator)在初始化时都会关联这个DCQS，每个线程都会关联一个DCQ。



DCQ的最大长度默认256，最多存放256个引用关系对象。在本线程中如果产生新的对象引用关系，则把引用者放入DCQ队列中。当本线程的DCQ队列满256个时，就把这个DCQ队列放入到DCQS中。DCQS可以被所有线程共享，所以放入DCQ时需要加锁。而DCQ的处理则是通过Refine线程来处理。



G1设计了一个二级缓存来解决DCQ写入引用关系变更数据时的并发冲突。第一层缓存是在线程这一层，每一个工作线程都会关联一个DCQ。每个线程在执行引用更新操作时，都会往自己那个DCQ里写入变更信息。



DCQ的长度默认是256，如果写满了，就重新申请一个新的DCQ，并把这个满了的DCQ提交到第二级缓存，也就是一个DCQ Set里面去。这个二级缓存叫DCQS，所以所谓的DCQS其实不过就是一个存放DCQ的地方。
